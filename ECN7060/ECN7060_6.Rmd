---
title: "ECN 6578, Cours 6"
author: "William McCausland"
date: "`r Sys.Date()`"
output: beamer_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Lemme de Fatou

* Lemme de Fatou : pour une suite $X_n \geq 0$ de v.a.
$$ E[\liminf_{n\to \infty} X_n] \leq \liminf_{n\to \infty} E[X_n]. $$

* Notes :
    1. Hypothèse très faible concernant $X_n$.
    1. Résultat pour $X_n \geq C > -\infty$ suit immédiatement.
    1. Les deux cotés peuvent être infinis.
    
* Construction d'une séquence convergente : $Y_n \equiv \inf_{k\geq n} X_k$.
    1. $0 \leq Y_n \leq X_n$.
    1. $Y_n \leq Y_{n+1}$ ($\{k \geq n\}$ décroissant).
    1. $Y_n \nearrow Y \equiv \liminf_{n\to \infty} X_n$.

* Preuve :
$$ \liminf_n E[X_n] \geq \liminf_n E[Y_n] = \lim_n E[Y_n] = E[Y] = E[\liminf_n X_n] $$

## Lemme de Fatou pour $X_n \leq C < \infty$

* Si $X_n \leq C < \infty$, $-X_n \geq -C > -\infty$ et par le lemme de Fatou,
\[
  \liminf_n E[-X_n] \geq E[\liminf_n -X_n],
\]
\[
  \liminf_n -E[X_n] \geq E[-\limsup_n X_n],
\]
\[
  -\limsup_n E[X_n] \geq -E[\limsup_n X_n],
\]
\[
  \limsup_n E[X_n] \leq E[\limsup_n X_n].
\]

## Théorème de convergence dominée

* Pour une séquence $X_n$ de variables aléatoires, $X$ et $Y$ v.a. telles que
$P(X_n \to X) = 1$, $|X_n| \leq Y$ et $E[Y] < \infty$.
$$ \lim_{n\to \infty} E[X_n] = E[X]. $$

* Notes :
    1. La condition avec $Y$ (dominance) plus faible que $|X_n|$ uniformement bornés ($Y=c$); le résultat est donc plus fort.
    1. Même v.a. dominante $Y$ pour tous les $n$.

* Preuve :
$$ E[Y] + E[X] = E[Y+X] = E[Y+\lim_n X_n] = E[Y+\liminf_n X_n] $$
$$ E[Y+\liminf_n X_n] \leq \liminf_n E[Y+X_n] = E[Y] + \liminf_n E[X_n] $$
$$ E[Y] - E[X] = \ldots \leq \ldots = E[Y] - \limsup_n E[X_n]. $$
$$ \limsup_n E[X_n] \leq E[X] \leq \liminf_n E[X_n]. $$
$$ \lim_n E[X_n] = E[X]. $$

## Remarque sur les ensembles non-dénombrables de variables aléatoires

* Soit $\{X_t\}_{t\geq 0}$, un ensemble non-dénombrable de variables aléatoires.
* Exemples :
    * $e^{sX}$, dont l'espérance est $M_X(s)$, une fonction de $s$ réel.
    * $X \sim N(\mu, \sigma^2)$, $\mu$ et $\sigma^2$ inconnus. $E[f(X)]$ est une fonction de $\mu$, $\sigma^2$.
* Supposons que
    * $\lim_{t \downarrow 0}X_t(\omega) = X(\omega)$, $\omega \in \Omega$,
    * il exist une v.a. $Y$ telle que $|X_t| < Y$ et $E[Y] < \infty$.
* Alors pour toute suite $t_n \downarrow 0$,
$$ E[X_{t_n}] \to E[X_0]. $$
* Alors
$$ \lim_{t\downarrow 0} E[X_t] = E[X_0]. $$

## La dérivée de l'espérance

* Soit $\{F_t\}_{a<t<b}$ un ensemble de variables aléatoires.
* Conditions suffisantes pour $\frac{dE[F_t]}{dt} = E[F_t']$ :
    1. Pour tout $t \in (a,b)$ : $-\infty < E[F_t] < \infty$.
    1. Il existe une v.a. $Y$ telle que $E[Y] < \infty$ et pour tous $t \in (a,b)$ et $\omega \in \Omega$, $F_t'(\omega)$ existe et $|F_t'(\omega)| \leq Y(\omega)$.
* Preuve : fixez $t\in (a,b)$. Alors
    1. $F_t' = \lim_{n\to \infty} n(F_{t+1/n}-F_t)$, la limite d'une séquence de
    variables aléatoires, est une variable alétoire.
    1. Pour tous $h$, $0 < h < b-t$,
    (théorème des accroissements finis, mean value theorem)
    $$ \left|\frac{F_{t+h}-F_t}{h}\right| \leq Y. $$
    1. Alors
    $$ \lim_{h \downarrow 0} \frac{E[F_{t+h}]-E[F_t]}{h}
    = \lim_{h \downarrow 0} E\left[\frac{F_{t+h}-F_t}{h}\right]
    = E\left[\lim_{h \downarrow 0} \frac{F_{t+h}-F_t}{h} \right] $$
    $$ \frac{dE[F_t]}{dt} = E[F_t'] \leq E[Y] < \infty. $$ 

## Fonction génératrice des moments

* Définition : pour une v.a. $X$, $M_X(s) = E[e^{sX}]$, $s\in R$.
* Notes
    * $M_X$ n'existe pas toujours, même si $E[X] < \infty$.
    * $M_{X+Y}(s) = M_X(s)M_Y(s)$ pour v.a. indépendentes $X,Y$.
    * il y a des tableaux avec plusieurs v.a. standardes
    * la fonction caractéristique est souvent plus utile

## Résultat sur $M_X(s)$

* Supposons que $X$ est une v.a. et qu'il existe $s_0 > 0$ tel que $M_X(s) < \infty$ pour $|s|<s_0$.
* Alors
$$ E[|X^n|] < \infty,\, M_X(s) = \sum_{n=0}^\infty E[X^n] s^n / n!. $$
* Preuve :
    1. Soit $Z_n = \sum_{k=0}^n (sX)^k / k!$.
    1. $Z_n \to e^{sX}$ (définition de somme infinie)
    1. Fixez $s$, $|s|<s_0$
    $$ |Z_n| \leq \sum_{k=0}^n |sX|^k / k! \leq e^{sX} + e^{-sX} \equiv Y, $$
    $$ E[Y] = M_X(s) + M_X(-s) < \infty. $$
    1. Par convergence dominée, $E[e^{sX}] = \lim_{n\to \infty} E[Z_n] = \sum_{n=0}^\infty E[X^n]s^n/n!$.
    
## Signification de « génératrice des moments »

* Rappel $M_X(s) = \sum_{n=0}^\infty E[X^n]s^n/n!$
* $M_X'(s) = \sum_{n=0}^\infty E[X^{n+1}]s^n/n!$
* $M_X^{(m)}(s) = \sum_{n=0}^\infty E[X^{n+m}]s^n/n!$
* $M_X(0) = 1$, $M_X'(0) = E[X]$, $M_X^{(m)}(0) = E[X^m]$.

## Mesures associées aux variables aléatoires

* Soit $X$ une variable aléatoire sur un espace de probabilité $(\Omega,{\cal F},P)$
* $(\mathbb{R}, {\cal B}, \mu)$ est un espace de probabilité elle aussi, où
$$ \mu = {\cal L}(X) = PX^{-1}. $$
* Si $B \in {\cal B}$, $X^{-1}(B) \in {\cal F}$ et $\mu(B) = P(X^{-1}(B)) = (PX^{-1})(B)$.
* Pour $-\infty \leq a \leq b \leq \infty$,
    * $[a,b] \subset \mathbb{R}$,
    * $[a,b] \in {\cal B}$,
    * $\mu([a,b]) = P(\{X \in [a,b]\}),$
    * $\{X \in [a,b]\} \subset \Omega$,
    * $\{X \in [a,b]\} \in {\cal F}$.

## Convergence en distribution

* Soit $\mu_n$ une séquence de mesures de probabilité boreliennes, $\mu$ une mesure de probabilité borelienne.
* $\mu_n \Rightarrow \mu$ ($\mu_n$ converge en distribution à $\mu$) si pour chaque fonction $f \colon \mathbb{R} \to \mathbb{R}$, continue et bornée,
$$ \int_{\mathbb{R}} f\, d\mu_n \to \int_{\mathbb{R}} f\, d\mu. $$
* Une condition équivalente: pour tout $x \in \mathbb{R}$,
$$ \mu(\{x\}) = 0 \Rightarrow F_n(x) \to F(x), $$
où $F_n(x) \equiv \mu_n((-\infty,x])$, $F(x) \equiv \mu((-\infty,x])$.
* $\mu_n$ est une suite de mesures, pas une suite de variables aléatoires.
* Cependant, si $X_n$ est une suite de variables aléatoires sur $(\Omega,{\cal F},P)$, ${\cal L}_n = PX_n^{-1}$ est une suite de mesures.

## Convergence en probabilité et en distribution

* Si $X_n \to X$ en probabilité,
$\mu_n \equiv {\cal L}(X_n) \Rightarrow {\cal L}(X) \equiv \mu$.
* Résultat équivalent : Si pour tout $\epsilon > 0$, $P(|X_n-X|\geq \epsilon) \to 0$,
$$ \mu(\{x\}) = 0 \Rightarrow F_n(x) \to F(x). $$
* Preuve : fixez $x \in \mathbb{R}$, $\epsilon > 0$. Alors pour tout $\omega \in \Omega$, $n \in \mathbb{N}$,
$$ X > x + \epsilon\;\mbox{et}\; |X_n - X| < \epsilon \Rightarrow X_n > x, $$
alors pour tout $n \in \mathbb{N}$,
$$ \{X_n \leq x\} \subseteq \{X \leq x + \epsilon\} \cup \{|X_n - X| \geq \epsilon\} $$
$$ F_n(x) \leq F(x+\epsilon) + P(|X_n-X| \geq \epsilon). $$
Puisque $\sup_n F_n(x) \leq F(x+\epsilon)$,
$$ \limsup_n F_n(x) \leq F(x+\epsilon) + 0, $$
et puisque $\epsilon > 0$ est arbitraire,
$$ \limsup_n F_n(x) \leq F(x). $$

## Preuve, continuée

* même $x \in \mathbb{R}$, fixez $\epsilon > 0$.
Pour tout $\omega \in \Omega$, $n \in \mathbb{N}$,
$$ X_n > x\;\mbox{et}\; |X_n-X| < \epsilon \Rightarrow X > x - \epsilon, $$
alors pour tout $n \in \mathbb{N}$,
$$ \{X \leq x-\epsilon\} \subseteq \{X_n \leq x\} \cup \{|X_n-X| \geq \epsilon\}, $$
alors
$$ F(x-\epsilon) \leq \liminf_n F_n(x) + \liminf_n P(|X_n-X| \geq \epsilon) $$
$$ F(x-\epsilon) \leq \liminf_n F_n(x) $$
* $\epsilon$ arbitraire, alors
$$ F(x) - P(\{x\}) \leq \liminf_n F_n(x) $$
* Maintenant si $P(\{x\}) = 0$,
$$ \liminf_n F_n(x) = \limsup_n F_n(x) = \lim_n F_n(x) = F(x) $$
