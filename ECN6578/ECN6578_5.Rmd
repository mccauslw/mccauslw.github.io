---
title: "ECN 6578A, Économétrie des marchés financiers, Hiver 2020"
subtitle: "Cours 5"
author: "William McCausland"
date: "`r Sys.Date()`"
output: beamer_presentation
---

## Plan

1. Maximum de vraisemblance : l'exemple le plus simple
1. Maximum de vraisemblance : un peu de théorie
1. Le modèle EGARCH
1. Estimation des modèles GARCH, quelques résultats

## Le modèle Bernoulli

* Supposons que les $y_i$ sont iid Bernoulli avec probabilité $\theta \in [0,1]$ :
\[
  \begin{aligned}
    f(y_i|\theta) &= \begin{cases} \theta & y_i = 1 \\ (1-\theta) & y_i = 0 \end{cases} \\
    &= \theta^{y_i}(1-\theta)^{1-y_i}
  \end{aligned}
\]
* On observe $y = (y_1,\ldots,y_n)$ ; la fonction de masse de probabilité est
\[
  f(y|\theta) = \prod_{i=1}^n f(y_i|\theta) = \prod_{i=1}^n \theta^{y_i} (1-\theta)^{1-y_i}
  = \theta^{n_1} (1-\theta)^{n_0},
\]
où
    - $n_1 = \sum_{i=1}^n y_i$ est le nombre de fois qu'on observe 1, et
    - $n_0 = n - \sum_{i=1}^n y_i$ est le nombre de fois qu'on observe 0.

## Deux intérpretations de la même expression

* Deux façons de dénoter la même expression :
    * Fonction de masse de probabilité $f(y|\theta) = \theta^{n_1} (1-\theta)^{n_0}$.
    * Fonction de vraisemblance ${\cal L}(\theta; y) = \theta^{n_1} (1-\theta)^{n_0}$.
* $f(y|\theta)$ donne, pour $\theta$ fixe, les probabilités relatives de plusieurs séquences $(y_1,\ldots,y_n)$.
* ${\cal L}(\theta; y)$ donne, pour $y$ fixe (le vecteur des données observées) une note (ou évaluation) à
chaque valeur $\theta$ pour la qualité de sa prévision des données observées.
* Soit $L(\theta; y) = \log {\cal L}(\theta; y)$, la log-vraisemblance.

## La vraisemblance Bernoulli pour $n_0 = 200$, $n_1 = 230$

```{r vrai}
n_0 = 200; n_1 = 230; theta = seq(0, 1, by=0.001)
L = theta^n_1 * (1-theta)^n_0
plot(theta, L, type='l')
```

## La log vraisemblance Bernoulli pour $n_0 = 200$, $n_1 = 230$

```{r lvrai}
logL = n_1 * log(theta) + n_0 * log(1-theta)
plot(theta, logL, type='l', ylim=c(-400, max(logL)))
```

## La fonction de vraisemblance pour une séries chronologique

* La vraisemblance en général pour un modèle qui donne la densité $f(r_1,\ldots,r_T,\theta)$.
\[
  {\cal L}(\theta; r) = f(r_1|\theta) f(r_2|r_1,\theta) \cdots f(r_T|r_1,\ldots,r_{T-1},\theta)
\]
* Chaque densité $f(r_t|r_1,\ldots,r_{t-1})$ est un genre de prévision conditionnelle de $r_t$ sachant $r_1,\ldots,r_{t-1}$.
* La log vraisemblance est
\[
  L(\theta; r) = \sum_{t=1}^T \log f(r_t|r_1,\ldots,r_{t-1},\theta).
\]
* Pourquoi la log-vraisemblance et non juste la vraisemblance?
    * Pas de underflow numérique (soupassement arithmétique)
    * Plus facile à maximiser (la dérivée d'une somme est la somme des dérivées)

## Exemple : évaluation de la log vraisemblance GARCH(1,1)

* Juste avant l'itération $t$ on a la valeur $\sigma_t^2$ et observe $r_t$.
* À l'itération $t$,

1. On calcule le terme $\log f(r_t|r_1,\ldots,r_{t-1})$ de la log vraisemblance.
Dans le cas gaussien,
\[
  \log f(r_t|r_1,\ldots,r_{t-1}) = -\tfrac{1}{2} (\log 2\pi + \log \sigma_t^2) - \tfrac{1}{2} r_t^2/\sigma_t^2.
\]
et plus en général,
\[
  \log f(r_t|r_1,\ldots,r_{t-1}) = -\log \sigma_t + \log f_\epsilon(r_t/\sigma_t),
\]
où $f_\epsilon(\epsilon)$ et la densité des $\epsilon_t$.
1. On calcule la valeur $\sigma_{t+1}^2$ :
\[
  \sigma_{t+1}^2 = \alpha_0 + \alpha_1 r_t^2 + \beta_1 \sigma_t^2.
\]

## Maximum de la vraisemblance Bernoulli

* Vraisemblance : ${\cal L}(\theta;y) = \theta^{n_1} (1-\theta)^{n_0}$.
* Log vraisemblance : $L(\theta;y) = n_1 \log(\theta) + n_0 \log(1-\theta)$
* Deux dérivées de la log vraisemblance :
\[
  \frac{\partial L(\theta;y)}{\partial \theta} = \frac{n_1}{\theta} - \frac{n_0}{1-\theta}
\]
\[
  \frac{\partial^2 L(\theta;y)}{\partial \theta^2} = -\frac{n_1}{\theta^2} - \frac{n_0}{(1-\theta)^2} < 0.
\]
* La valeur qui maximise la vraisemblance et la log-vraisemblance est
\[
  \hat{\theta} = \frac{n_1}{n_0 + n_1}.
\]

## Maximum de vraisemblance : conditions de régularité

* Définitions :
    * $\theta$ est le vecteur des paramètres ; $\Theta$, l'ensemble de toutes les valeurs possibles de $\theta$.
    * $r$ est le vecteur (aléatoire) des données.

* Conditions informelles de regularité :
    1. Le modèle est correct pour une valeur $\theta = \theta_0 \in \Theta$.
    1. La vraie valeur $\theta_0$ est dans l'intérieur de $\Theta$.
    1. Identification :
    $$ \theta \neq \theta_0 \Rightarrow f(\cdot|\theta) \neq f(\cdot|\theta_0). $$
    1. $L(\theta;r) \equiv \log f(r|\theta)$ a toujours un maximum global unique.
    1. Le gradient de $L(\theta;r)$ est toujours borné.
    1. La matrice ${\cal I}(\theta)$ suivante (matrice d'information de Fisher) est définie positive:
    $$ {\cal I}(\theta) = E_{r|\theta}\left[ \frac{\partial L(\theta;r)}{\partial \theta^\top} \frac{\partial L(\theta;r)}{\partial \theta} \right]. $$

## Maximum de vraisemblance : résultats

Résultats :

1. $\hat{\theta} = \arg \max_{\theta} L(\theta;r)$ existe, est unique.
1. $\hat{\theta} \to_p \theta_0$ (loi de grands nombres)
1. $\sqrt{n}(\hat{\theta}-\theta_0) \to_d N(0,{\cal I}(\theta_0)^{-1})$ (théorème central limite)
1. $E_{r|\theta}\left[\frac{\partial L(\theta;r)}{\partial \theta}\right] = 0$, alors ${\cal I}(\theta) = \mathrm{Var}_{r|\theta}\left[\frac{\partial L(\theta;r)}{\partial \theta}\right]$.
1. ${\cal I}(\theta)  = E_{r|\theta}\left[ -\frac{\partial^2 L(\theta;r)}{\partial \theta \partial \theta^\top} \right].$

Problèmes restants :

1. Il faut trouver $\hat{\theta}$.
1. La variance asymptotique ${\cal I}(\theta_0)^{-1}$ dépend de $\theta_0$, qui est inconnu.
1. L'espérance dans l'expression de ${\cal I}(\theta)$ est difficile à évaluer analytiquement.

## Exemple Bernoulli

* La moyenne du score :
\[
  E_{y|\theta}\left[\frac{\partial L}{\partial \theta}\right]
  = E_{y|\theta}\left[\frac{n_1}{\theta} - \frac{n_0}{(1-\theta)}\right]
  = \frac{n\theta}{\theta} - \frac{n(1-\theta)}{(1-\theta)}
  = 0
\]
* La matrice d'information de Fisher :
\[
  \begin{aligned}
  {\cal I}(\theta)
  &= E_{y|\theta}\left[-\frac{\partial^2 L}{\partial \theta^2}\right]
  = E_{y|\theta}\left[\frac{n_1}{\theta^2} + \frac{n_0}{(1-\theta)^2}\right] \\
  &= \frac{n\theta}{\theta^2} + \frac{n(1-\theta)}{(1-\theta)^2}
  = \frac{n}{\theta(1-\theta)}.
  \end{aligned}
\]
* La variance de $\hat{\theta}$ (exacte, pas asymptotique) :
\[
  \mathrm{Var}[\hat{\theta}] = \mathrm{Var}\left[\frac{n_1}{n}\right]
  = \frac{1}{n^2} n \mathrm{Var}[y_i] = \frac{1}{n} (\theta-\theta^2) = \frac{\theta(1-\theta)}{n}.
\]

## Comment trouver $\hat{\theta}$ I

* Gradient (score) et hessienne de la log-vraisemblance :
$$ s(\theta) \equiv \frac{\partial L(\theta;r)}{\partial \theta^\top},\quad H(\theta) \equiv
\frac{\partial^2 L(\theta;r)}{\partial \theta \partial \theta^\top}. $$
* Processus iteratif pour trouver $\hat{\theta}$ : $\theta_1, \theta_2, \ldots,$
* Approximation quadratique local autour de $\theta_k$ :
$$ \tilde{L}(\theta;r) = L(\theta_k;r) + s(\theta_k)^\top (\theta-\theta_k) + \frac{1}{2} (\theta-\theta_k)^\top H(\theta_k) (\theta - \theta_k). $$
* Le gradient $\tilde{s}(\theta)$ de $\tilde{L}(\theta;r)$ :
$$ \tilde{s}(\theta) = s(\theta_k) + H(\theta_k) (\theta - \theta_k) $$
* $\tilde{s}(\theta_{k+1}) = 0$ définit $\theta_{k+1}$ de la méthode Newton :
$$ \theta_{k+1} = \theta_k - H(\theta_k)^{-1} s(\theta_k). $$

## Comment trouver $\hat{\theta}$ II

* Problème de non-convergence si la forme de la vraisemblance est loin de quadratique.

* Solution de BHHH : choisir une valeur scalaire $\lambda_k$ et calculer
$$ \theta_{k+1} = \theta_k - \lambda_k H(\theta_k) s(\theta_k). $$
    1. Calculez $s(\theta_k)$, $H(\theta_k)$.
    1. Trouvez une bonne valeur de $\lambda_k$ (recherche linéaire)

* Des fois, on utilise souvent, au lieu de $H(\theta)$,
$$ \hat{H}(\theta) = -\sum_{t=1}^T
\frac{\partial \log f(r_t|r_1,\ldots,r_{t-1},\theta)}{\partial \theta^\top}
\frac{\partial \log f(r_t|r_1,\ldots,r_{t-1},\theta)}{\partial \theta}. $$
* Avec $r_t$ indépendents, une loi de grands nombres donne $$ \hat{H}(\theta_0) \to_p E[s(\theta_0)s(\theta_0)^\top] = {\cal I}(\theta_0) = - E[H(\theta_0)]. $$

## Approximation de ${\cal I}(\theta_0)$

* On utilise $H(\hat{\theta})$ ou $\hat{H}(\hat{\theta})$ au lieu de
${\cal I}(\theta_0)$, qui est inconnu.

* Convergence de $\hat{\theta}$ à $\theta_0$.

* Convergence de $\hat{H}(\theta_0)$ ou $H(\theta_0)$ à ${\cal I}(\theta_0) = E[H(\theta_0)]$.

* Ensemble, convergence de $H(\hat\theta)$ ou $\hat{H}(\hat{\theta})$ à ${\cal I}(\theta_0)$.

## Le modèle EGARCH

Le modèle EGARCH(1,1) :
\[
  a_t = \sigma_t \epsilon_t
  \quad \ln \sigma^2_t = \alpha \ln \sigma^2_{t-1} + (1-\alpha) \alpha_0 + g(\epsilon_t)
  \quad \epsilon_t \sim (0,1),
\]
où $g(\epsilon) = \theta \epsilon + \gamma [|\epsilon| - E[|\epsilon|]]$.

Notes :

* $E[\epsilon_t] = 0$, $E[|\epsilon_t| - E[|\epsilon_t|]] = 0$, $E[g(\epsilon_t)] = 0$.
* Par exemple, si $\epsilon_t \sim N(0,1)$, $E[|\epsilon_t|] = \sqrt{2/\pi}$
* $\ln \sigma_t^2$ est un processus AR(1).
* Pour $\theta < 0$, il y a un effet de levier.
* Pas besoin de contraintes pour assurer la positivité de la volatilité.

## La fonction $g(\epsilon)$ de l'équation (3.31) (un exemple)

```{r geps, echo=TRUE}
eps = seq(-3, 3, by=0.01)
theta = -0.0795; gamma = 0.2647
g = theta * eps + gamma * (abs(eps) - sqrt(2/pi))
plot(eps, g, type='l'); abline(h=0, lty=2)
```

## Ajustement de plusieurs modèles GARCH (code)

```
library(fGarch)
# Séries IBM journalière, log rendements 1962-97
r = scan('d-ibmln.txt')

# GARCH(1, 1) gaussien
gn = garchFit(~garch(1,1), cond.dist='norm', data=r)

# mu_t : ARMA(1, 0), sigma_t : GARCH(1, 1) gaussien
agn = garchFit(~arma(1,0)+garch(1,1), cond.dist='norm', data=r)

# GARCH(1, 1) t de Student
gt = garchFit(~garch(1,1), cond.dist='std', data=r)
```

```{r prepare, message=FALSE, warning=FALSE, include=FALSE}
library(fGarch)
# Séries IBM journalière, log rendements 1962-97
r = scan('d-ibmln.txt')

# GARCH(1, 1) gaussien
gn = garchFit(~garch(1,1), cond.dist='norm', data=r)

# mu_t : ARMA(1, 0), sigma_t : GARCH(1, 1) gaussien
agn = garchFit(~arma(1,0)+garch(1,1), cond.dist='norm', data=r)

# GARCH(1, 1) t de Student
gt = garchFit(~garch(1,1), cond.dist='std', data=r)
```

## Données IBM journalière, $r_t$

```{r gn_r}
plot(gn, which=1)
```

## GARCH(1,1) gaussien, $\hat{\sigma}_t$

```{r gn_s}
plot(gn, which=2)
```

## GARCH(1,1) gaussien, $\hat{\epsilon}_t$

```{r gn_e}
plot(gn, which=9)
```

## GARCH(1,1) gaussien, ACF($r_t^2$)

```{r gn_acfr2}
acf(r^2)
```

## GARCH(1,1) gaussien, ACF($\hat{\epsilon}^2_t$)

```{r gn_acfe2}
plot(gn, which=11)
```

## GARCH(1,1) gaussien, graphique Q-Q pour $\hat{\epsilon}_t$

```{r gn_acfQQ}
plot(gn, which=13)
```

## GARCH(1,1) gaussien, sommaire des résultats

* Le modèle capture bien l'autodépendence de volatilité.
* Le modèle capture mal l'asymétrie et surtout l'aplatissement conditionnel.

## GARCH(1,1) $t$ de Student, $\hat{\epsilon}_t$

```{r gt_e}
plot(gt, which=9)
```

## GARCH(1,1) $t$ de Student, graphique Q-Q pour $\hat{\epsilon}_t$

```{r gt_acfQQ}
plot(gt, which=13)
```

## GARCH(1,1) $t$ de Student, sommaire des résultats

* Le modèle capture mieux l'aplatissement conditionnel que le modèle GARCH(1,1) gaussien,
* mais pas parfaitement :
    - le modèle ne capture pas bien les (mettons) 10 valeurs les plus extrêmes (sur $\approx$ 9000)
    - il y a plus de valeurs extrêmes que prévu par le modèle (mauvaise spécification de l'évolution de la variance conditionnelle $\sigma_t$ ou de la loi conditionnelle ou des deux?)
* Une asymétrie : les valeurs extrêmes négatives sont particulièrement extrêmes.

## Cours 6, après la semaine d'activités libres

### Plan préliminaire
1. Introduction à l'inférence bayésienne
1. Modèles de volatilité stochastique
